{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1137a936-4d26-4c06-b163-c00a3dcb9aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hii my name is ishita jain and currently I am  learning NLP.\n",
      "I live in bhopal. where are you from?\n"
     ]
    }
   ],
   "source": [
    "corpus=\"\"\"hii my name is ishita jain and currently I am  learning NLP.\n",
    "I live in bhopal. where are you from?\"\"\"\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cc8a738-cae9-4349-b08a-d852dfbf5f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hii my name is ishita jain and currently I am  learning NLP.\n",
      "I live in bhopal.\n",
      "where are you from?\n"
     ]
    }
   ],
   "source": [
    "#convert paragraph into sentence\n",
    "from nltk.tokenize import sent_tokenize\n",
    "sentence=sent_tokenize(corpus)\n",
    "for s in sentence:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0eff50c9-b5ee-4dc1-858c-6227fb2664e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hii\n",
      "my\n",
      "name\n",
      "is\n",
      "ishita\n",
      "jain\n",
      "and\n",
      "currently\n",
      "I\n",
      "am\n",
      "learning\n",
      "NLP\n",
      ".\n",
      "I\n",
      "live\n",
      "in\n",
      "bhopal\n",
      ".\n",
      "where\n",
      "are\n",
      "you\n",
      "from\n",
      "?\n"
     ]
    }
   ],
   "source": [
    "#convert paragraph into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "sentence=word_tokenize(corpus)\n",
    "for s in sentence:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72287596-05f2-44c0-af4f-8b6339dd8a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hii\n",
      "my\n",
      "name\n",
      "is\n",
      "ishita\n",
      "jain\n",
      "and\n",
      "currently\n",
      "I\n",
      "am\n",
      "learning\n",
      "NLP\n",
      ".\n",
      "I\n",
      "live\n",
      "in\n",
      "bhopal\n",
      ".\n",
      "where\n",
      "are\n",
      "you\n",
      "from\n",
      "?\n"
     ]
    }
   ],
   "source": [
    "#wordpunct tokenizer\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "sentence=wordpunct_tokenize(corpus)\n",
    "for s in sentence:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b54785c0-7ba3-4528-ae99-98260450ed85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hii',\n",
       " 'my',\n",
       " 'name',\n",
       " 'is',\n",
       " 'ishita',\n",
       " 'jain',\n",
       " 'and',\n",
       " 'currently',\n",
       " 'I',\n",
       " 'am',\n",
       " 'learning',\n",
       " 'NLP.',\n",
       " 'I',\n",
       " 'live',\n",
       " 'in',\n",
       " 'bhopal.',\n",
       " 'where',\n",
       " 'are',\n",
       " 'you',\n",
       " 'from',\n",
       " '?']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TreebankWord tokenizer tokenizer\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "sentence=TreebankWordTokenizer()\n",
    "sentence.tokenize(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6ac3e79-bf0c-480e-aefd-05d8d587f0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello everyone.', 'I am implementing NLP with Python Language.', 'Many assignments are pending and I will complete them today itself.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "text=\"Hello everyone. I am implementing NLP with Python Language. Many assignments are pending and I will complete them today itself.\"\n",
    "print(sent_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9c922da-51be-44a9-88f9-0e3620d6ed2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello everyone.\n",
      "['Hello', 'everyone', '.'] \n",
      "\n",
      "I am implementing NLP with Python Language.\n",
      "['I', 'am', 'implementing', 'NLP', 'with', 'Python', 'Language', '.'] \n",
      "\n",
      "Many assignments are pending and I will complete them today itself.\n",
      "['Many', 'assignments', 'are', 'pending', 'and', 'I', 'will', 'complete', 'them', 'today', 'itself', '.'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sents=sent_tokenize(text)\n",
    "for s in sents:\n",
    "    print(s)\n",
    "    words=word_tokenize(s)\n",
    "    print(words,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33843ecb-2855-4838-8746-d20b9c0d4f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your text i am a girl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length is 4\n"
     ]
    }
   ],
   "source": [
    "text1=input(\"Enter your text\")\n",
    "print(\"The length is\",len(word_tokenize(text1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd5afa1b-1d32-4af1-b34a-93a50b20b988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Many assignments are pending and I'll complete them today itself.\"]\n"
     ]
    }
   ],
   "source": [
    "tokenizer=nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "text=\"Many assignments are pending and I'll complete them today itself.\"\n",
    "print(tokenizer.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18899b95-3e72-4caa-bbf6-8e28808192d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Many', 'assignments', 'are', 'pending', 'and', 'I', \"'ll\", 'complete', 'them', 'today', 'itself', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "tokenizer=TreebankWordTokenizer()\n",
    "print(tokenizer.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e8e364a-3e92-4715-87ee-99f31a45a633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Many', 'assignments', 'are', 'pending', 'and', 'I', \"'\", 'll', 'complete', 'them', 'today', 'itself', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tokenizer=WordPunctTokenizer()\n",
    "print(tokenizer.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a60564d1-dea4-4f63-95c1-21c72d83d579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Many', 'assignments', 'are', 'pending', 'and', \"I'll\", 'complete', 'them', 'today', 'itself']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer= RegexpTokenizer(\"[\\w']+\")\n",
    "print(tokenizer.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3cf1865b-4e38-4c9e-a9a4-7fbcf953220b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Many', 'assignments', 'are', 'pending', 'and', \"I'll\", 'complete', 'them', 'today', 'itself.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "tokenizer=WhitespaceTokenizer()\n",
    "print(tokenizer.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a05fed57-eea2-4695-a5ad-e39ba0522fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Many', 'assignments', 'are', 'pending', 'and', \"I'll\", 'complete', 'them', 'today', 'itself.']\n",
      "['Many', 'assignments', 'are', 'pending', 'and', \"I'll\", 'complete', 'them', 'today', 'itself.']\n",
      "[\"Many assignments are pending and I'll complete them today itself.\"]\n"
     ]
    }
   ],
   "source": [
    "print(text.split())\n",
    "print(text.split(' '))\n",
    "print(text.split('\\n'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef2071b7-78bf-4ec5-8750-ffc6eba44be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Many assignments are pending and I'll complete them today itself.\"]\n",
      "[\"Many assignments are pending and I'll complete them today itself.\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import LineTokenizer\n",
    "print(LineTokenizer(blanklines='keep').tokenize(text))\n",
    "print(LineTokenizer(blanklines='discard').tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9b726fc-a059-4eda-8051-001c99cc6b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Many', 'assignments', 'are', 'pending', 'and', \"I'll\", 'complete', 'them', 'today', 'itself.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import SpaceTokenizer\n",
    "print(SpaceTokenizer().tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d42de19-61f3-4209-9549-785071caf773",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81df8bef-8970-46bb-8167-8f1fc1edf8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['albanian', 'arabic', 'azerbaijani', 'basque', 'belarusian', 'bengali', 'catalan', 'chinese', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'greek', 'hebrew', 'hinglish', 'hungarian', 'indonesian', 'italian', 'kazakh', 'nepali', 'norwegian', 'portuguese', 'romanian', 'russian', 'slovene', 'spanish', 'swedish', 'tajik', 'tamil', 'turkish', 'uzbek']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "print(stopwords.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5570627b-5e06-4e7b-832d-130c09c6ae3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Many\n",
      "assignments\n",
      "pending\n",
      "I'll\n",
      "complete\n",
      "today\n",
      "itself.\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stops=set(stopwords.words('english'))\n",
    "text=['Many', 'assignments', 'are', 'pending', 'and', \"I'll\", 'complete', 'them', 'today', 'itself.']\n",
    "for word in text:\n",
    "    if word not in stops:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "808ef2ea-5dbc-439d-afb7-b8feeb2af5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Many', 'assignments', 'pending', \"I'll\", 'complete', 'today', 'itself.']\n",
      "Many\n",
      "assignments\n",
      "pending\n",
      "I'll\n",
      "complete\n",
      "today\n",
      "itself.\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stops=set(stopwords.words('english'))\n",
    "text=['Many', 'assignments', 'are', 'pending', 'and', \"I'll\", 'complete', 'them', 'today', 'itself.']\n",
    "print([word for word in text if word not in stops])\n",
    "for word in text:\n",
    "    if word not in stops:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58bde6b1-767d-4fcd-af02-0e72b636c675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.8\n"
     ]
    }
   ],
   "source": [
    "from nltk.metrics import *\n",
    "training='PERSON OTHER PERSON OTHER OTHER ORGANIZATION'.split()\n",
    "testing='PERSON OTHER OTHER OTHER OTHER OTHER'.split()\n",
    "print(accuracy(training,testing))\n",
    "trainset=set(training)\n",
    "testset=set(testing)\n",
    "precision(trainset,testset)\n",
    "print(recall(trainset,testset))\n",
    "print(f_measure(trainset,testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da9a38e8-a5ea-4cc5-b799-cfaed212430f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "from nltk.metrics import *\n",
    "print(edit_distance(\"relate\",\"relation\"))\n",
    "print(edit_distance(\"suggestion\",\"calculation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "60793b05-7c71-4d15-adee-db7987f7ab56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n"
     ]
    }
   ],
   "source": [
    "from nltk.metrics import *\n",
    "X=set([10,20,30,40])\n",
    "Y=set([20,30,60])\n",
    "print(jaccard_distance(X,Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "88f84cd1-1966-408e-a15c-953393b6439c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from nltk.metrics import *\n",
    "X = set([10,20,30,40])\n",
    "Y= set([30,50,70])\n",
    "print(binary_distance(X, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c227a6-ce60-4e96-b070-30e60ed455a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
