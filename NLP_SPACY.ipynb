{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "8FAEhodlq20v",
        "outputId": "d78cf041-2b0e-4d18-d8e5-fccdfb97dc8d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'spacy.tokens.token.Token' object is not iterable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3102120827.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dr. Strange loves pav bhaji in mumbai. Hulk loved Chai of bhopal\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'spacy.tokens.token.Token' object is not iterable"
          ]
        }
      ],
      "source": [
        "#sentence tokenization in spacy\n",
        "import spacy\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "doc=nlp(\"Dr. Strange loves pav bhaji in mumbai. Hulk loved Chai of bhopal\")\n",
        "for sent in doc:\n",
        "    for word in sent:\n",
        "        print(word)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycm_OvSBq7sh",
        "outputId": "752f3ca1-9881-4e7e-9393-c9f463ebf162"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.11)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.21.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (4.67.3)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.12.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (26.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2026.1.4)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim<1.0.0,>=0.3.0->spacy) (8.3.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.1.1)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sentence tokenization in spacy\n",
        "import spacy\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "doc=nlp(\"Dr. Strange loves pav bhaji in mumbai. Hulk loved Chai of bhopal\")\n",
        "for sent in doc.sents:\n",
        "    for word in sent:\n",
        "        print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hiDOp8erRni",
        "outputId": "0ad34a61-b396-48c3-8bf6-5ba3c6a32f10"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dr.\n",
            "Strange\n",
            "loves\n",
            "pav\n",
            "bhaji\n",
            "in\n",
            "mumbai\n",
            ".\n",
            "Hulk\n",
            "loved\n",
            "Chai\n",
            "of\n",
            "bhopal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "    print(token.text, token.pos, token.lemma_,token.is_stop)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WX5Gfq16rn4z",
        "outputId": "2b5bf1a0-1f69-4d93-b1cc-7e782f9cc531"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dr. 96 Dr. False\n",
            "Strange 96 Strange False\n",
            "loves 100 love False\n",
            "pav 92 pav False\n",
            "bhaji 92 bhaji False\n",
            "in 85 in True\n",
            "mumbai 92 mumbai False\n",
            ". 97 . False\n",
            "Hulk 96 Hulk False\n",
            "loved 100 love False\n",
            "Chai 96 Chai False\n",
            "of 85 of True\n",
            "bhopal 92 bhopal False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for ext in doc.ents:\n",
        "    print(ext.text, ext.label_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvegvpmCrqMz",
        "outputId": "3a079912-9b3b-4bb5-8b87-3b7c68b3c66c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Strange PERSON\n",
            "mumbai GPE\n",
            "Hulk ORG\n",
            "Chai PERSON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "    print(token.text, token.dep_,token.head.text,token.head.pos_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_mUm0Bzrsej",
        "outputId": "6bafac0b-c51e-4458-e8bb-048af84ebda7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dr. compound Strange PROPN\n",
            "Strange nsubj loves VERB\n",
            "loves ROOT loves VERB\n",
            "pav compound bhaji NOUN\n",
            "bhaji dobj loves VERB\n",
            "in prep bhaji NOUN\n",
            "mumbai pobj in ADP\n",
            ". punct loves VERB\n",
            "Hulk nsubj loved VERB\n",
            "loved ROOT loved VERB\n",
            "Chai dobj loved VERB\n",
            "of prep Chai PROPN\n",
            "bhopal pobj of ADP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word1=nlp(\"cat\")\n",
        "word2=nlp(\"dog\")\n",
        "print(word1.similarity(word2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2YNJH7Frvd7",
        "outputId": "725f6d61-4daa-4384-d4c9-fe6cca8fe31b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7422727346420288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3405947277.py:3: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  print(word1.similarity(word2))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "displacy.render(doc,style=\"dep\",jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "35_FWr-Ory44",
        "outputId": "9f6e7554-f1e5-449d-e42e-8461d0d27a36"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"d1de3f21b0ac40a496de023ac34eadf7-0\" class=\"displacy\" width=\"2150\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Dr.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">Strange</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">loves</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">pav</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">bhaji</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">in</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">mumbai.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">Hulk</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">loved</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">Chai</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">of</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">bhopal</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-d1de3f21b0ac40a496de023ac34eadf7-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-d1de3f21b0ac40a496de023ac34eadf7-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-d1de3f21b0ac40a496de023ac34eadf7-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-d1de3f21b0ac40a496de023ac34eadf7-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-d1de3f21b0ac40a496de023ac34eadf7-0-2\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-d1de3f21b0ac40a496de023ac34eadf7-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M595,179.0 L587,167.0 603,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-d1de3f21b0ac40a496de023ac34eadf7-0-3\" stroke-width=\"2px\" d=\"M420,177.0 C420,2.0 750.0,2.0 750.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-d1de3f21b0ac40a496de023ac34eadf7-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M750.0,179.0 L758.0,167.0 742.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-d1de3f21b0ac40a496de023ac34eadf7-0-4\" stroke-width=\"2px\" d=\"M770,177.0 C770,89.5 920.0,89.5 920.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-d1de3f21b0ac40a496de023ac34eadf7-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M920.0,179.0 L928.0,167.0 912.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-d1de3f21b0ac40a496de023ac34eadf7-0-5\" stroke-width=\"2px\" d=\"M945,177.0 C945,89.5 1095.0,89.5 1095.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-d1de3f21b0ac40a496de023ac34eadf7-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1095.0,179.0 L1103.0,167.0 1087.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-d1de3f21b0ac40a496de023ac34eadf7-0-6\" stroke-width=\"2px\" d=\"M1295,177.0 C1295,89.5 1445.0,89.5 1445.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-d1de3f21b0ac40a496de023ac34eadf7-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1295,179.0 L1287,167.0 1303,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-d1de3f21b0ac40a496de023ac34eadf7-0-7\" stroke-width=\"2px\" d=\"M1470,177.0 C1470,89.5 1620.0,89.5 1620.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-d1de3f21b0ac40a496de023ac34eadf7-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1620.0,179.0 L1628.0,167.0 1612.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-d1de3f21b0ac40a496de023ac34eadf7-0-8\" stroke-width=\"2px\" d=\"M1645,177.0 C1645,89.5 1795.0,89.5 1795.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-d1de3f21b0ac40a496de023ac34eadf7-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1795.0,179.0 L1803.0,167.0 1787.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-d1de3f21b0ac40a496de023ac34eadf7-0-9\" stroke-width=\"2px\" d=\"M1820,177.0 C1820,89.5 1970.0,89.5 1970.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-d1de3f21b0ac40a496de023ac34eadf7-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1970.0,179.0 L1978.0,167.0 1962.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sentence tokenization using spacy\n",
        "for sent in doc.sents:\n",
        "    print(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-m-xGpor0a6",
        "outputId": "df6727a4-9e49-4c72-9ba3-70cb924a10bf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dr. Strange loves pav bhaji in mumbai.\n",
            "Hulk loved Chai of bhopal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in doc.noun_chunks:\n",
        "    print(chunk.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZv1UnaVr4Ag",
        "outputId": "0c617052-be2e-4b44-c908-71cb4b693f7f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dr. Strange\n",
            "pav bhaji\n",
            "mumbai\n",
            "Hulk\n",
            "Chai\n",
            "bhopal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZMedmkmpsAEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3qsVhnGEsAAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "    print(token.text, token.has_vector,token.vector_norm,token.is_oov) #oov=out of verb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9y5Xlj3r6Ea",
        "outputId": "170eb84e-9554-445b-9275-d39039bf727f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dr. True 7.5668054 True\n",
            "Strange True 7.4168606 True\n",
            "loves True 7.0972342 True\n",
            "pav True 5.527973 True\n",
            "bhaji True 4.7130647 True\n",
            "in True 6.047654 True\n",
            "mumbai True 5.896344 True\n",
            ". True 9.212772 True\n",
            "Hulk True 8.278206 True\n",
            "loved True 6.7709074 True\n",
            "Chai True 6.1944475 True\n",
            "of True 7.1324067 True\n",
            "bhopal True 5.9016275 True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.en.stop_words import STOP_WORDS"
      ],
      "metadata": {
        "id": "JAV81Vd3sErw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(STOP_WORDS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iQFYJ9ZsLcc",
        "outputId": "807b471b-bfbf-42f0-b13d-5f91a5889ad5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'each', 'through', \"n't\", 'towards', 'whereafter', 'one', 'whereas', 'so', 'whose', 'yourselves', 'afterwards', 'six', 'nobody', 'anyone', 'myself', 'about', 'could', 'throughout', 'out', 'the', '‘ve', 'such', 'that', \"'m\", 'seems', 'next', 'without', 'side', 'upon', 'here', 'others', 'i', 'fifty', 'must', 'show', 'therein', 'elsewhere', 'more', 'bottom', '‘d', 'anyhow', '’m', 'had', 'none', 'never', 'and', 'where', 'should', 'therefore', \"'s\", 'nowhere', 'thereupon', 'together', 'nor', 'otherwise', 'everything', 'twelve', 'whatever', 'became', 'someone', 'neither', 'often', 'on', 'in', 'why', 'forty', 'fifteen', 'is', 'would', 'become', 'hundred', 'please', 'eleven', 'under', 'besides', 'but', 'toward', 'only', 'beforehand', 'even', 'except', 'since', 'twenty', 'across', 'his', 'get', 'first', \"'re\", 'former', 'beyond', 'they', 'yet', 'enough', 'because', 'whither', 'put', 'not', 'between', 'my', 'formerly', 'whereby', 'being', 'whence', 'using', 'while', 'back', 'which', 'full', '’re', 'beside', 'we', 'yourself', 'wherein', 'same', 'be', 'seemed', 'various', 'by', 'wherever', 'everyone', 'every', 'both', 'herein', 'see', 'ten', \"'ll\", 'what', 'ours', 'somewhere', 'least', 'rather', 'three', 'amount', 'thereby', 'name', 'thereafter', 'say', 'hereupon', 'few', 'our', 'over', 'everywhere', 'two', 'than', '’s', 'although', 'within', 'around', 'before', 'whether', 'third', 'mine', 'yours', 'anywhere', 'due', 'themselves', 'latter', 'ca', 'will', 'via', 'might', 'unless', 'nine', 'us', 'very', 'with', '‘s', 'during', 'whenever', 'me', 'when', 'along', 'still', 'himself', 'sometime', 'latterly', 'thru', 'for', 'sometimes', 'empty', 'namely', 'further', 'who', 'he', 'any', 'it', 'does', 'him', 'have', 'of', '’ll', 'somehow', 'made', 'are', 'this', 'part', 'among', '‘re', 'above', 'once', 'hence', 'mostly', 'now', 'do', 'up', 'into', '‘m', 'five', 'seem', 'cannot', 'as', 're', 'make', 'at', 'from', 'own', 'been', 'front', 'can', 'their', 'becomes', 'has', 'may', 'less', 'almost', 'well', '’d', 'keep', 'whole', 'indeed', \"'d\", 'just', 'amongst', 'some', 'these', 'there', 'already', 'sixty', 'eight', 'top', 'she', 'or', 'quite', 'how', 'your', 'alone', 'much', 'whereupon', 'n‘t', 'call', 'thus', 'last', 'becoming', 'anything', 'too', 'regarding', 'ever', 'however', 'against', 'hereby', 'other', 'was', 'ourselves', 'n’t', 'whom', 'were', 'to', 'an', 'behind', 'another', 'if', 'many', 'nothing', 'serious', 'take', 'below', 'doing', 'go', 'also', 'four', 'am', '‘ll', 'those', 'though', 'down', 'meanwhile', 'them', 'no', 'a', 'always', 'something', 'itself', 'several', 'onto', 'all', 'nevertheless', 'whoever', 'off', 'per', 'again', \"'ve\", 'move', 'really', '’ve', 'did', 'either', 'its', 'noone', 'then', 'moreover', 'used', 'most', 'done', 'thence', 'you', 'hers', 'after', 'anyway', 'else', 'give', 'hereafter', 'her', 'seeming', 'until', 'herself', 'perhaps'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.vocab[\"the\"].is_stop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qv02TagZsNFq",
        "outputId": "44d1ee4c-d802-4123-bde6-67923ce73b96"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mysentence = nlp(u\"This is a group of word to check for stop words\")\n",
        "for word in mysentence:\n",
        "    if word.is_stop == True:\n",
        "        print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxc_X8uhsOnN",
        "outputId": "9b543d21-4fd3-489b-85cb-fb9e8508c4ba"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This\n",
            "is\n",
            "a\n",
            "of\n",
            "to\n",
            "for\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filterdwords = []\n",
        "for word in mysentence:\n",
        "    if word.is_stop == False:\n",
        "        print(word)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78-BYFCesQFb",
        "outputId": "30077e83-0c63-4c67-8bf1-3ae5d38c2f40"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "group\n",
            "word\n",
            "check\n",
            "stop\n",
            "words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#WAP to count the number of sentences in an input text\n",
        "import spacy\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "text=input(\"Enter your statement:\")\n",
        "tokens=nlp(text)\n",
        "c=0\n",
        "for s in tokens.sents:\n",
        "    c+=1\n",
        "print(\"No of sentences:\",c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwsiggBGsRxf",
        "outputId": "2fed6b2e-32de-4807-d4d2-54b0bd6ce4ef"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your statement:I am a girl. My name is ishita. I live in Bhopal. I study at banasthali vidyapith.\n",
            "No of sentences: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#WAP to print each sentence along with its sentence index (1..N) and sentence length (number of tokens).\n",
        "\n",
        "def length(s):\n",
        "    c=0\n",
        "    for token in s:\n",
        "        c+=1\n",
        "    return c\n",
        "\n",
        "import spacy\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "text=input(\"Enter your statement:\")\n",
        "tokens=nlp(text)\n",
        "c=0\n",
        "for s in tokens.sents:\n",
        "    print(\"Sentence index:\",c)\n",
        "    c+=1\n",
        "    print(\"Sentence:\",s)\n",
        "    print(\"Length\",length(s))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SONNR4DkscVf",
        "outputId": "d7c6aee6-353f-4333-8658-d3e701d9a711"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your statement:I am a girl. My name is ishita. I live in Bhopal. I study at banasthali vidyapith.\n",
            "Sentence index: 0\n",
            "Sentence: I am a girl.\n",
            "Length 5\n",
            "Sentence index: 1\n",
            "Sentence: My name is ishita.\n",
            "Length 5\n",
            "Sentence index: 2\n",
            "Sentence: I live in Bhopal.\n",
            "Length 5\n",
            "Sentence index: 3\n",
            "Sentence: I study at banasthali vidyapith.\n",
            "Length 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#WAP to find the longest and shortest sentence (by token count) and print them.\n",
        "\n",
        "\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "text = input(\"Enter your statement: \")\n",
        "doc = nlp(text)\n",
        "\n",
        "sentences = []\n",
        "lengths = []\n",
        "\n",
        "# store sentences and their lengths\n",
        "for i, sent in enumerate(doc.sents, start=1):\n",
        "    token_count = len(sent)\n",
        "    sentences.append(sent)\n",
        "    lengths.append(token_count)\n",
        "\n",
        "# find longest and shortest\n",
        "max_index = lengths.index(max(lengths))\n",
        "min_index = lengths.index(min(lengths))\n",
        "\n",
        "print(\"Longest sentence:\", sentences[max_index])\n",
        "print(\"Length:\", lengths[max_index])\n",
        "\n",
        "print(\"Shortest sentence:\", sentences[min_index])\n",
        "print(\"Length:\", lengths[min_index])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhQEn6yfsiPw",
        "outputId": "337f1512-e180-48c7-dcce-69f14754d0cd"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your statement: I live in Bhopal. I study at banasthali vidyapith.\n",
            "Longest sentence: I study at banasthali vidyapith.\n",
            "Length: 6\n",
            "Shortest sentence: I live in Bhopal.\n",
            "Length: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#WAP to count how many sentences are questions, exclamations, and statements (based on ending punctuation ?\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "text = input(\"Enter your statement: \")\n",
        "doc = nlp(text)\n",
        "\n",
        "questions = 0\n",
        "statements = 0\n",
        "exclamations = 0\n",
        "\n",
        "for sent in doc.sents:\n",
        "    sentence = str(sent).strip()\n",
        "\n",
        "    if sentence.endswith('?'):\n",
        "        questions += 1\n",
        "    elif sentence.endswith('!'):\n",
        "        exclamations += 1\n",
        "    elif sentence.endswith('.'):\n",
        "        statements += 1\n",
        "\n",
        "print(\"Questions:\", questions)\n",
        "print(\"Statements:\", statements)\n",
        "print(\"Exclamations:\", exclamations)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAYCONXJtJ3J",
        "outputId": "a7bd2a97-7cc9-4c83-dc79-24443fdcfd24"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your statement: I am great. how are you? well done!\n",
            "Questions: 1\n",
            "Statements: 1\n",
            "Exclamations: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#WAP to count the number of tokens whose lemma is different from the surface form.\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "text=input(\"Enter your statement:\")\n",
        "tokens=nlp(text)\n",
        "c=0\n",
        "for s in tokens:\n",
        "    if s.lemma_ !=s:\n",
        "        c+=1\n",
        "print(\"Different\",c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7bvYt99tgeW",
        "outputId": "bf0b851b-90da-4065-c592-1cf01f324c35"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your statement:i am great. playing ans eating\n",
            "Different 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#WAP to compute the lemma diversity: #unique lemmas / #unique tokens (ignore punctuation + spaces).\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "text=input(\"Enter your statement:\")\n",
        "tokens=nlp(text)\n",
        "stem=[]\n",
        "stem=[s.lemma_ for s in tokens]\n",
        "print(\"Lemma Diversity:\",len(set(stem))/len(set(tokens)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NXEflVqtrpJ",
        "outputId": "becb11fa-00ad-4de2-9662-94f701b31b0b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your statement:i am a girl\n",
            "Lemma Diversity: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#WAP to count the number of NOUN, PROPN, PRON separately and total “noun-like” count.\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "text=input(\"Enter your statement:\")\n",
        "tokens=nlp(text)\n",
        "stem=[s.lemma_ for s in tokens]\n",
        "n=0\n",
        "p=0\n",
        "pn=0\n",
        "for s in tokens:\n",
        "    if s.pos_==\"NOUN\":\n",
        "        n+=1\n",
        "    elif s.pos_==\"PROPN\":\n",
        "        p+=1\n",
        "    elif s.pos_==\"PRON\":\n",
        "        pn+=1\n",
        "print(\"NOUN:\",n,\"PROPN\",p,\"PRON\",pn)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLKnhUIztu_7",
        "outputId": "3daec173-e2ec-44af-e9a9-930b067b0ea5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your statement:i am a gurl. he is a boy\n",
            "NOUN: 2 PROPN 0 PRON 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#WAP to count VERB vs AUX separately, and total “verb-like” count.\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "text=input(\"Enter your statement:\")\n",
        "tokens=nlp(text)\n",
        "stem=[s.lemma_ for s in tokens]\n",
        "v=0\n",
        "aux=0\n",
        "for s in tokens:\n",
        "    if s.pos_==\"VERB\":\n",
        "        v+=1\n",
        "    elif s.pos_==\"AUX\":\n",
        "        aux+=1\n",
        "print(\"VERB:\",v,\"AUX\",aux)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOn1KLPktybD",
        "outputId": "6c950ede-347b-4f4d-a1aa-81a49a50306a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your statement:i am eating and watching \n",
            "VERB: 2 AUX 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#WAP to print the top 10 most frequent nouns and top 10 most frequent verbs (by lemma, ignoring stopwords/punct).\n",
        "import spacy\n",
        "from collections import Counter\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "text = input(\"Enter your statement: \")\n",
        "doc = nlp(text)\n",
        "\n",
        "noun_freq = Counter()\n",
        "verb_freq = Counter()\n",
        "\n",
        "for token in doc:\n",
        "    # ignore stopwords and punctuation\n",
        "    if token.is_stop or token.is_punct:\n",
        "        continue\n",
        "\n",
        "    # count nouns (by lemma)\n",
        "    if token.pos_ in [\"NOUN\", \"PROPN\"]:\n",
        "        noun_freq[token.lemma_.lower()] += 1\n",
        "\n",
        "    # count verbs (by lemma)\n",
        "    elif token.pos_ == \"VERB\":\n",
        "        verb_freq[token.lemma_.lower()] += 1\n",
        "\n",
        "print(\"Top 10 Nouns:\")\n",
        "print(noun_freq.most_common(10))\n",
        "\n",
        "print(\"\\nTop 10 Verbs:\")\n",
        "print(verb_freq.most_common(10))\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bU6-GQhNtz9F",
        "outputId": "0418a7e2-21d3-4408-f2bb-472f2ef13622"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your statement: i am a girl and i am studying\n",
            "Top 10 Nouns:\n",
            "[('girl', 1)]\n",
            "\n",
            "Top 10 Verbs:\n",
            "[('study', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#WAP to compute the percentage of nouns in the text:denominator = total non-space, non-punct tokens\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "text = input(\"Enter your statement: \")\n",
        "doc = nlp(text)\n",
        "\n",
        "total_tokens = 0\n",
        "noun_count = 0\n",
        "\n",
        "for token in doc:\n",
        "    # ignore spaces and punctuation\n",
        "    if token.is_space or token.is_punct:\n",
        "        continue\n",
        "\n",
        "    total_tokens += 1\n",
        "\n",
        "    if token.pos_ == \"NOUN\":\n",
        "        noun_count += 1\n",
        "\n",
        "percentage = (noun_count / total_tokens) * 100 if total_tokens > 0 else 0\n",
        "\n",
        "print(\"Total tokens (non-space, non-punct):\", total_tokens)\n",
        "print(\"Noun count:\", noun_count)\n",
        "print(\"Percentage of nouns:\", percentage)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CidruWFmuPZ_",
        "outputId": "4e67f2da-36aa-4d0c-d515-50b02a276a79"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your statement: i am a girl\n",
            "Total tokens (non-space, non-punct): 4\n",
            "Noun count: 1\n",
            "Percentage of nouns: 25.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#WAP to count the number of different Penn POS tags present in the text using token.tag_ and print the set.\n",
        "penn_tags = set(t.tag_ for t in doc )\n",
        "print(len(penn_tags))\n",
        "print(penn_tags)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrrvIjbTuiY8",
        "outputId": "5839f90b-38eb-43c0-861f-d9e48902d9f5"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "{'NN', 'PRP', 'DT', 'VBP'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#WAP to count the number of different Universal POS tags present and print the set.\n",
        "upos = set(t.pos_ for t in doc if not t.is_space and not t.is_punct)\n",
        "print(len(upos))\n",
        "print(upos)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mv_CQvajukdc",
        "outputId": "a3eea810-035c-43f9-c619-83f856a34cf2"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "{'AUX', 'NOUN', 'DET', 'PRON'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#WAP to print a mapping summary: for each Universal POS, list which Penn tags appeared under it (e.g., NOUN -> {NN, NNS, ...}).\n",
        "from collections import defaultdict\n",
        "\n",
        "mapping = defaultdict(set)\n",
        "\n",
        "for t in doc:\n",
        "    if not t.is_space and not t.is_punct:\n",
        "        mapping[t.pos_].add(t.tag_)\n",
        "\n",
        "for k, v in mapping.items():\n",
        "    print(k, \"->\", v)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqFiLx_Eum8i",
        "outputId": "1a2e71d1-0d14-4c80-b796-3abdbeda82b8"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PRON -> {'PRP'}\n",
            "AUX -> {'VBP'}\n",
            "DET -> {'DT'}\n",
            "NOUN -> {'NN'}\n"
          ]
        }
      ]
    }
  ]
}